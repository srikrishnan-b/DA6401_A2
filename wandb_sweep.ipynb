{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11318637,"sourceType":"datasetVersion","datasetId":7079686}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install lightning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:04:51.362849Z","iopub.execute_input":"2025-04-12T05:04:51.363454Z","iopub.status.idle":"2025-04-12T05:06:04.943187Z","shell.execute_reply.started":"2025-04-12T05:04:51.363431Z","shell.execute_reply":"2025-04-12T05:06:04.942474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Subset, DataLoader\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport torchvision\nimport torchvision.transforms.v2 as v2\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport lightning as pl\nfrom torchmetrics import Accuracy\nfrom lightning.pytorch.loggers import WandbLogger\nfrom lightning.pytorch import Trainer\nimport wandb\nimport shutil\nimport numpy as np\nimport random\nimport gc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:06:17.873718Z","iopub.execute_input":"2025-04-12T05:06:17.873971Z","iopub.status.idle":"2025-04-12T05:06:17.878552Z","shell.execute_reply.started":"2025-04-12T05:06:17.873946Z","shell.execute_reply":"2025-04-12T05:06:17.877863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ['WANDB_API_KEY'] = \"761e2f0f9986fd2e6ee9f21ef44a2665e0bc8618\"\nwandb.login(key=os.getenv(\"WANDB_API_KEY\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:06:17.880379Z","iopub.execute_input":"2025-04-12T05:06:17.881005Z","iopub.status.idle":"2025-04-12T05:06:23.662094Z","shell.execute_reply.started":"2025-04-12T05:06:17.880986Z","shell.execute_reply":"2025-04-12T05:06:23.661525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/inaturalist12k'\ntarget_dir = '/kaggle/temp/inaturalist12k'\n\nif not os.path.exists(target_dir):\n    shutil.copytree(data_dir, target_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:06:23.662701Z","iopub.execute_input":"2025-04-12T05:06:23.663087Z","iopub.status.idle":"2025-04-12T05:07:55.524108Z","shell.execute_reply.started":"2025-04-12T05:06:23.663069Z","shell.execute_reply":"2025-04-12T05:07:55.523496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transforms(augmentation):  \n   if augmentation:\n       transform = v2.Compose(\n       [v2.Resize((256, 256)),\n        v2.RandomHorizontalFlip(p=0.4),\n        #v2.RandomVerticalFlip(p=0.5),\n        #v2.RandomRotation(degrees=45),\n        #v2.ColorJitter(brightness=0.2, contrast=0.2),\n        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n        v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n   else:\n        transform = v2.Compose(\n        [v2.Resize((256, 256)),\n        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n        v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n    \n\n   return transform\n\n\"\"\"elif augmentation == \"hflip\":\n    augment = v2.RandomHorizontalFlip(p=0.5)\n  elif augmentation == 'vflip':\n    augment = v2.RandomVerticalFlip(p=0.5)\n  elif augmentation == 'rotate':\n    augment = v2.RandomRotation(degrees=45)\n\n  transform = v2.Compose(\n    [v2.Resize((256, 256)),\n     v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n     augment,\n     v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n  )\n  return transform\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:55.524860Z","iopub.execute_input":"2025-04-12T05:07:55.525122Z","iopub.status.idle":"2025-04-12T05:07:55.532486Z","shell.execute_reply.started":"2025-04-12T05:07:55.525091Z","shell.execute_reply":"2025-04-12T05:07:55.531752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_WORKERS = 0\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:55.533243Z","iopub.execute_input":"2025-04-12T05:07:55.533630Z","iopub.status.idle":"2025-04-12T05:07:56.484018Z","shell.execute_reply.started":"2025-04-12T05:07:55.533605Z","shell.execute_reply":"2025-04-12T05:07:56.483272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"batch_size = 32\n\n\ntransform = transforms(augmentation='hflip')\nDATA_DIR = \"/kaggle/temp/inaturalist12k/inaturalist_12K\"\ntrain_dataset_complete = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"train\"), transform=transform)\ntest_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"val\"), transform=transform)\n\n# Getting labels and random splitting/shuffling of each class examples\nlabels = np.array([entry[1] for entry in train_dataset_complete.samples])\nsplit_fn = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 219)\ntrain_ids, valid_ids = next(split_fn.split(np.zeros(len(labels)), labels))\n\ntrain_dataset = Subset(train_dataset_complete, train_ids)\nvalid_dataset = Subset(train_dataset_complete, valid_ids)\n\n\n# Dataloader\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                          shuffle=True, num_workers=NUM_WORKERS, pin_memory = True)\n\nval_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size,\n                                         shuffle=False, num_workers=NUM_WORKERS, pin_memory= True)\n\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False, num_workers=NUM_WORKERS, pin_memory= True)\n\nclasses = train_dataset_complete.classes\nn_classes = len(classes)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T05:02:44.120014Z","iopub.execute_input":"2025-04-11T05:02:44.120785Z","iopub.status.idle":"2025-04-11T05:02:44.163398Z","shell.execute_reply.started":"2025-04-11T05:02:44.120753Z","shell.execute_reply":"2025-04-11T05:02:44.162685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"def imgplot(data):\n  images, labels = next(iter(data))\n  plt.figure(figsize=(8,8))\n  samples = []\n  for i in range(len(images)):\n    img = images[i]/2 + 0.5\n    if labels[i] in samples:\n      continue\n    else:\n      samples.append(labels[i])\n      plt.subplot(2,5,len(samples))\n      plt.imshow(img.permute(1,2,0))\n      plt.axis('off')\n      plt.title(classes[labels[i]])\n    if len(samples) == n_classes:\n      break\n  plt.tight_layout()\n  plt.show()\n\n\nimgplot(train_dataloader)\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, input, filters, kernel, pool_kernel, pool_stride, batchnorm, activation, dropout, ffn_size, num_classes=10):\n        super().__init__()\n        \n        self.act = self._activation(activation)\n        self.convblock1 = self._convblock(input, filters[0], kernel[0], pool_kernel[0], pool_stride[0], self.act, batchnorm, dropout)\n        self.convblock2 = self._convblock(filters[0], filters[1], kernel[1], pool_kernel[1], pool_stride[1], self.act, batchnorm, dropout)\n        self.convblock3 = self._convblock(filters[1], filters[2], kernel[2], pool_kernel[2], pool_stride[2], self.act, batchnorm, dropout)\n        self.convblock4 = self._convblock(filters[2], filters[3], kernel[3], pool_kernel[3], pool_stride[3], self.act, batchnorm, dropout)\n        self.convblock5 = self._convblock(filters[3], filters[4], kernel[4], pool_kernel[4], pool_stride[4], self.act, batchnorm, dropout)\n        if batchnorm:\n            self.batch_norm = nn.BatchNorm1d(num_features=ffn_size)\n        else:\n            self.batch_norm = nn.Identity()\n\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.LazyLinear(ffn_size)\n        self.out = nn.Linear(ffn_size, num_classes)\n\n    def _convblock(self, input, output, kernel, pool_kernel, pool_stride, activation_fn,  batchnorm, dropout=0):\n\n        if batchnorm:\n          return torch.nn.Sequential(\n              nn.Conv2d(input, output, kernel),\n  \n              activation_fn,\n              nn.BatchNorm2d(output),\n              nn.Dropout(dropout),\n              nn.MaxPool2d(pool_kernel, pool_stride))\n        else:\n          return torch.nn.Sequential(\n              nn.Conv2d(input, output, kernel),\n              activation_fn,\n              nn.Dropout(dropout),\n              nn.MaxPool2d(pool_kernel, pool_stride))\n\n    def _activation(self, act):\n        if act == 'relu':\n            act = nn.ReLU()\n        elif act == 'gelu':\n            act = nn.GELU()\n        elif act == 'selu':\n            act = nn.SELU()\n        elif act == 'mish':\n            act = nn.Mish()\n        elif act == 'swish':\n            act = nn.SiLU()\n        return act\n\n    def forward(self, x):\n        x = self.convblock1(x)\n        x = self.convblock2(x)\n        x = self.convblock3(x)\n        x = self.convblock4(x)\n        x = self.convblock5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        x = self.batch_norm(x)\n        x = self.act(x)\n        x = self.dropout(x)\n        x = self.out(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:56.484866Z","iopub.execute_input":"2025-04-12T05:07:56.485393Z","iopub.status.idle":"2025-04-12T05:07:56.499580Z","shell.execute_reply.started":"2025-04-12T05:07:56.485369Z","shell.execute_reply":"2025-04-12T05:07:56.498853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN_light(pl.LightningModule):\n    def __init__(self, optim, filters, kernel, pool_kernel, pool_stride, batchnorm, activation, dropout, ffn_size, lr):\n        super().__init__()\n        self.optim = optim\n        self.save_hyperparameters()\n        self.model = CNN(input=3, filters=filters, kernel=kernel, pool_kernel=pool_kernel, pool_stride=pool_stride, batchnorm=batchnorm, activation=activation, dropout=dropout, ffn_size=ffn_size, num_classes=10)\n        self.train_accuracy = Accuracy(task='multiclass', num_classes=10)\n        self.val_accuracy = Accuracy(task='multiclass', num_classes=10)\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        acc = self.train_accuracy(logits, y)\n        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n        self.log(\"train accuracy\", acc, on_step = False, on_epoch = True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n        acc = self.val_accuracy(logits, y)\n        self.log(\"val loss\", loss, on_step = False, on_epoch = True)\n        self.log(\"val accuracy\", acc, on_step = False, on_epoch = True)\n\n        return loss\n\n    def configure_optimizers(self):\n        if self.optim == 'sgd':\n            optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9)\n        elif self.optim == 'adam':\n            optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n        return optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:56.500355Z","iopub.execute_input":"2025-04-12T05:07:56.500673Z","iopub.status.idle":"2025-04-12T05:07:56.518693Z","shell.execute_reply.started":"2025-04-12T05:07:56.500648Z","shell.execute_reply":"2025-04-12T05:07:56.518061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"model = CNN_light(optim = 'sgd', filters = [32,64,128,256,256], kernel=[3,3,3,5,5], pool_kernel=[2,2,2,3,3], pool_stride=[1,1,1,2,2], batchnorm=True, activation='relu', dropout=0.4, ffn_size=256, lr =0.0001)\nlogger= WandbLogger(project= 'dlas2test', name = \"test2\",resume=\"never\", id=None)\ntrainer = pl.Trainer(max_epochs=5,  accelerator=\"gpu\",logger=logger, profiler=None) #precision=\"16-mixed\",\ntrainer.fit(model, train_dataloader, val_dataloader)\nwandb.finish()\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T05:23:53.788380Z","iopub.execute_input":"2025-04-11T05:23:53.788671Z","iopub.status.idle":"2025-04-11T05:27:35.712584Z","shell.execute_reply.started":"2025-04-11T05:23:53.788651Z","shell.execute_reply":"2025-04-11T05:27:35.711820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sweeps","metadata":{}},{"cell_type":"code","source":"filters_des = {'same_8': [8,8,8,8,8], 'same_16':[16,16,16,16,16], 'same_32': [32,32,32,32,32], 'same_64': [64, 64, 64, 64, 64], 'increase_16_256':[16, 32, 64, 128, 128], 'decrease_256_16': [128, 128, 64, 32, 16], 'mixed': [16, 32, 64, 32, 16]}\nkernels_des = {'same_3': [3,3,3,3,3], 'same_5':[5,5,5,5,5], 'mix_3_5':[3,3,5,5,5]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:56.520504Z","iopub.execute_input":"2025-04-12T05:07:56.521265Z","iopub.status.idle":"2025-04-12T05:07:56.536230Z","shell.execute_reply.started":"2025-04-12T05:07:56.521239Z","shell.execute_reply":"2025-04-12T05:07:56.535521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    #'name': 'bayes_sweep_init',\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_acc',\n        'goal': 'maximize'\n    },\n    'early_terminate': {\n        'type': 'hyperband',\n        'min_iter': 3},\n    'parameters': {\n        'lr': {\n            'min': 1e-5,\n            'max': 1e-3\n        },\n        'batch_size': {\n            'values': [16,32]\n        },\n        'filters': {\n            'values': [\n                filters_des['same_8'],\n                filters_des['same_16'],\n                filters_des['same_32'],\n                filters_des['same_64'],\n                filters_des['increase_16_128'],\n                filters_des['decrease_128_16'],\n                filters_des['mixed']\n            ]\n        },\n        'kernel': {\n            'values': [\n                kernels_des['same_3'],\n                kernels_des['same_5'],\n                #kernels_des['same_7'],\n                kernels_des['mix_3_5']\n            ]\n        },\n        'pool_kernel': {\n            'values': [[2,2,2,2,2], [3,3,3,3,3], [2,2,2,3,3]]\n        },\n        'pool_stride': {\n            'values': [[1,1,1,1,1], [1,1,1,2,2],[1,1,1,1,2]]\n        },\n        'batchnorm': {\n            'values': [True, False]\n        },\n        'activation': {\n            'values': ['relu', 'gelu', 'selu', 'mish', 'swish']\n        },\n\n        'augmentation': {\n            'values': [True, False]\n        },\n        'dropout': {\n            'min': 0.0,\n            'max': 0.4\n        },\n        'ffn_size': {\n            'values': [64,128, 256]\n        },\n        'epochs': {'values': [5,10]},\n        'optim': {'values': ['sgd', 'adam']}\n    }\n}\n\n#'augmentation': {\n#    'values': ['hflip', 'vflip', 'rotate', None]\n#},","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:56.536989Z","iopub.execute_input":"2025-04-12T05:07:56.537641Z","iopub.status.idle":"2025-04-12T05:07:56.555328Z","shell.execute_reply.started":"2025-04-12T05:07:56.537619Z","shell.execute_reply":"2025-04-12T05:07:56.554783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Augmentation(torch.utils.data.Dataset):\n    def __init__(self, train_complete, indices, transform):\n        self.train_complete = train_complete\n        self.indices = indices\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        actual_idx = self.indices[idx]\n        image, label = self.train_complete[actual_idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:07:56.556302Z","iopub.execute_input":"2025-04-12T05:07:56.556571Z","iopub.status.idle":"2025-04-12T05:07:56.573148Z","shell.execute_reply.started":"2025-04-12T05:07:56.556556Z","shell.execute_reply":"2025-04-12T05:07:56.572535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def trainCNN(config=None):\n    with wandb.init(config=config) as run:\n        config = wandb.config\n        \n        run.name = f\"A_{config.augmentation}_D_{config.dropout:.2f}_bn_{config.batchnorm}_ffn_{config.ffn_size}\"\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n        try:\n            # Dataloading\n            train_transform = transforms(augmentation=config.augmentation)\n            val_transform = transforms(augmentation=False)\n            DATA_DIR = \"/kaggle/temp/inaturalist12k/inaturalist_12K\"\n            train_dataset_complete = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"train\"))\n            test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"val\"))\n        \n            # Getting labels and random splitting/shuffling of each class examples\n            labels = np.array([entry[1] for entry in train_dataset_complete.samples])\n            split_fn = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 219)\n            train_ids, valid_ids = next(split_fn.split(np.zeros(len(labels)), labels))\n        \n            #train_dataset = Subset(train_dataset_complete, train_ids)\n            #alid_dataset = Subset(train_dataset_complete, valid_ids)\n\n            # Transforms\n            train_dataset = Augmentation(train_dataset_complete, train_ids, train_transform)\n            valid_dataset = Augmentation(train_dataset_complete, valid_ids, val_transform)\n\n        \n            # Dataloader\n            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size,\n                                                      shuffle=True, num_workers=NUM_WORKERS, pin_memory = False, worker_init_fn=seed_worker,\n                generator=g)\n        \n            val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size,\n                                                    shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n                generator=g)\n        \n            test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n                                                    shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n                generator=g)\n        \n            classes = train_dataset_complete.classes\n            n_classes = len(classes)\n        \n        \n            # Model\n            model = CNN_light(optim= config.optim, filters= config.filters, kernel = config.kernel, pool_kernel=config.pool_kernel, pool_stride=config.pool_stride, batchnorm=config.batchnorm, activation=config.activation, dropout=config.dropout, ffn_size=config.ffn_size, lr=config.lr)\n            logger= WandbLogger(project= 'dlas2_sweeps', name = run.name, experiment=run, log_model = False)\n            trainer = pl.Trainer(\n                                    devices=1,\n                                    accelerator=\"gpu\",\n                                    #strategy=\"ddp_notebook\",\n                                    precision=\"16-mixed\",\n                                    gradient_clip_val=1.0,\n                                    max_epochs=config.epochs,\n                                    logger=logger,\n                                    profiler=None,\n                                    \n                                )\n\n            trainer.fit(model, train_dataloader, val_dataloader)\n        finally:\n            del trainer\n            del model\n            gc.collect()\n            torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:09:51.218849Z","iopub.execute_input":"2025-04-12T05:09:51.219123Z","iopub.status.idle":"2025-04-12T05:09:51.228244Z","shell.execute_reply.started":"2025-04-12T05:09:51.219103Z","shell.execute_reply":"2025-04-12T05:09:51.227501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"dla2-sweeps\")\n#sweep_id = \"deeplearn24/dla2-sweeps/9pjx0avr\"\nwandb.agent(sweep_id, function=trainCNN, count=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T05:09:55.999854Z","iopub.execute_input":"2025-04-12T05:09:56.000114Z","iopub.status.idle":"2025-04-12T05:13:14.540928Z","shell.execute_reply.started":"2025-04-12T05:09:56.000098Z","shell.execute_reply":"2025-04-12T05:13:14.539864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### To do\n- ResNET\n- vis filters","metadata":{}}]}