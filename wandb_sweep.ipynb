{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T05:04:51.363454Z",
     "iopub.status.busy": "2025-04-12T05:04:51.362849Z",
     "iopub.status.idle": "2025-04-12T05:06:04.943187Z",
     "shell.execute_reply": "2025-04-12T05:06:04.942474Z",
     "shell.execute_reply.started": "2025-04-12T05:04:51.363431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:06:17.873971Z",
     "iopub.status.busy": "2025-04-12T05:06:17.873718Z",
     "iopub.status.idle": "2025-04-12T05:06:17.878552Z",
     "shell.execute_reply": "2025-04-12T05:06:17.877863Z",
     "shell.execute_reply.started": "2025-04-12T05:06:17.873946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "import wandb\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:06:17.881005Z",
     "iopub.status.busy": "2025-04-12T05:06:17.880379Z",
     "iopub.status.idle": "2025-04-12T05:06:23.662094Z",
     "shell.execute_reply": "2025-04-12T05:06:23.661525Z",
     "shell.execute_reply.started": "2025-04-12T05:06:17.880986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"761e2f0f9986fd2e6ee9f21ef44a2665e0bc8618\"\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:06:23.663087Z",
     "iopub.status.busy": "2025-04-12T05:06:23.662701Z",
     "iopub.status.idle": "2025-04-12T05:07:55.524108Z",
     "shell.execute_reply": "2025-04-12T05:07:55.523496Z",
     "shell.execute_reply.started": "2025-04-12T05:06:23.663069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/inaturalist12k'\n",
    "target_dir = '/kaggle/temp/inaturalist12k'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    shutil.copytree(data_dir, target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:55.525122Z",
     "iopub.status.busy": "2025-04-12T05:07:55.524860Z",
     "iopub.status.idle": "2025-04-12T05:07:55.532486Z",
     "shell.execute_reply": "2025-04-12T05:07:55.531752Z",
     "shell.execute_reply.started": "2025-04-12T05:07:55.525091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transforms(augmentation):  \n",
    "   if augmentation:\n",
    "       transform = v2.Compose(\n",
    "       [v2.Resize((256, 256)),\n",
    "        v2.RandomHorizontalFlip(p=0.4),\n",
    "        v2.RandomVerticalFlip(p=0.1),\n",
    "        v2.RandomApply(\n",
    "        [v2.RandomRotation(degrees=15)],\n",
    "        p=0.1\n",
    "        ),\n",
    "        v2.RandomApply(\n",
    "        [v2.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                        saturation=0.2, hue=0.1)],\n",
    "        p=0.5\n",
    "        ),\n",
    "        #v2.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "   else:\n",
    "        transform = v2.Compose(\n",
    "        [v2.Resize((256, 256)),\n",
    "        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "    \n",
    "\n",
    "   return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_complete, indices, transform):\n",
    "        self.train_complete = train_complete\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        image, label = self.train_complete[actual_idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:55.533630Z",
     "iopub.status.busy": "2025-04-12T05:07:55.533243Z",
     "iopub.status.idle": "2025-04-12T05:07:56.484018Z",
     "shell.execute_reply": "2025-04-12T05:07:56.483272Z",
     "shell.execute_reply.started": "2025-04-12T05:07:55.533605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:56.485393Z",
     "iopub.status.busy": "2025-04-12T05:07:56.484866Z",
     "iopub.status.idle": "2025-04-12T05:07:56.499580Z",
     "shell.execute_reply": "2025-04-12T05:07:56.498853Z",
     "shell.execute_reply.started": "2025-04-12T05:07:56.485369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input, filters, kernel, pool_kernel, pool_stride, batchnorm, activation, dropout, ffn_size, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act = self._activation(activation)\n",
    "        self.convblock1 = self._convblock(input, filters[0], kernel[0], pool_kernel[0], pool_stride[0], self.act, batchnorm, dropout)\n",
    "        self.convblock2 = self._convblock(filters[0], filters[1], kernel[1], pool_kernel[1], pool_stride[1], self.act, batchnorm, dropout)\n",
    "        self.convblock3 = self._convblock(filters[1], filters[2], kernel[2], pool_kernel[2], pool_stride[2], self.act, batchnorm, dropout)\n",
    "        self.convblock4 = self._convblock(filters[2], filters[3], kernel[3], pool_kernel[3], pool_stride[3], self.act, batchnorm, dropout)\n",
    "        self.convblock5 = self._convblock(filters[3], filters[4], kernel[4], pool_kernel[4], pool_stride[4], self.act, batchnorm, dropout)\n",
    "        if batchnorm:\n",
    "            self.batch_norm = nn.BatchNorm1d(num_features=ffn_size)\n",
    "        else:\n",
    "            self.batch_norm = nn.Identity()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.LazyLinear(ffn_size)\n",
    "        self.out = nn.Linear(ffn_size, num_classes)\n",
    "\n",
    "    def _convblock(self, input, output, kernel, pool_kernel, pool_stride, activation_fn,  batchnorm, dropout=0):\n",
    "\n",
    "        if batchnorm:\n",
    "          return torch.nn.Sequential(\n",
    "              nn.Conv2d(input, output, kernel),\n",
    "  \n",
    "              activation_fn,\n",
    "              nn.BatchNorm2d(output),\n",
    "              #nn.Dropout(dropout),\n",
    "              nn.MaxPool2d(pool_kernel, pool_stride))\n",
    "        else:\n",
    "          return torch.nn.Sequential(\n",
    "              nn.Conv2d(input, output, kernel),\n",
    "              activation_fn,\n",
    "              #nn.Dropout(dropout),\n",
    "              nn.MaxPool2d(pool_kernel, pool_stride))\n",
    "\n",
    "    def _activation(self, act):\n",
    "        if act == 'relu':\n",
    "            act = nn.ReLU()\n",
    "        elif act == 'gelu':\n",
    "            act = nn.GELU()\n",
    "        elif act == 'selu':\n",
    "            act = nn.SELU()\n",
    "        elif act == 'mish':\n",
    "            act = nn.Mish()\n",
    "        elif act == 'swish':\n",
    "            act = nn.SiLU()\n",
    "        return act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.convblock5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:56.500673Z",
     "iopub.status.busy": "2025-04-12T05:07:56.500355Z",
     "iopub.status.idle": "2025-04-12T05:07:56.518693Z",
     "shell.execute_reply": "2025-04-12T05:07:56.518061Z",
     "shell.execute_reply.started": "2025-04-12T05:07:56.500648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN_light(pl.LightningModule):\n",
    "    def __init__(self, optim, filters, kernel, pool_kernel, pool_stride, batchnorm, activation, dropout, ffn_size, lr):\n",
    "        super().__init__()\n",
    "        self.optim = optim\n",
    "        self.save_hyperparameters()\n",
    "        self.model = CNN(input=3, filters=filters, kernel=kernel, pool_kernel=pool_kernel, pool_stride=pool_stride, batchnorm=batchnorm, activation=activation, dropout=dropout, ffn_size=ffn_size, num_classes=10)\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = self.train_accuracy(logits, y)\n",
    "        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"train accuracy\", acc, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = self.val_accuracy(logits, y)\n",
    "        self.log(\"val loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"val accuracy\", acc, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9)\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = True\n",
    "batch_size = 16\n",
    "optim = 'adam'\n",
    "filters = [64, 64, 64, 64, 64]\n",
    "kernel = [5,5,5,5,5]\n",
    "pool_kernel = [3,3,3,3,3]\n",
    "pool_stride = [1,1,1,1,2]\n",
    "batchnorm = True\n",
    "activation = 'mish'\n",
    "dropout = 0.4\n",
    "ffn_size = 256\n",
    "lr = 0.00005\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms(augmentation=aug)\n",
    "val_transform = transforms(augmentation=False)\n",
    "test_transform = transforms(augmentation=False)\n",
    "DATA_DIR = \"/kaggle/temp/inaturalist12k/inaturalist_12K\"\n",
    "train_dataset_complete = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"train\"))\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"val\"), transform=test_transform)\n",
    "\n",
    "# Getting labels and random splitting/shuffling of each class examples\n",
    "labels = np.array([entry[1] for entry in train_dataset_complete.samples])\n",
    "split_fn = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 219)\n",
    "train_ids, valid_ids = next(split_fn.split(np.zeros(len(labels)), labels))\n",
    "\n",
    "#train_dataset = Subset(train_dataset_complete, train_ids)\n",
    "#alid_dataset = Subset(train_dataset_complete, valid_ids)\n",
    "\n",
    "# Transforms\n",
    "train_dataset = Augmentation(train_dataset_complete, train_ids, train_transform)\n",
    "valid_dataset = Augmentation(train_dataset_complete, valid_ids, val_transform)\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=NUM_WORKERS, pin_memory = False, worker_init_fn=seed_worker,\n",
    "    generator=g)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n",
    "    generator=g)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                        shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n",
    "    generator=g)\n",
    "\n",
    "classes = train_dataset_complete.classes\n",
    "n_classes = len(classes)\n",
    "\n",
    "\n",
    "# Model\n",
    "model = CNN_light(optim= optim, filters= filters, kernel = kernel, pool_kernel=pool_kernel, pool_stride=pool_stride, batchnorm=batchnorm, activation=activation, dropout=dropout, ffn_size=ffn_size, lr=lr)\n",
    "logger= WandbLogger(project= 'scratch_test', name = 'best_val_acc', log_model = False)\n",
    "trainer = pl.Trainer(\n",
    "                        devices=1,\n",
    "                        accelerator=\"gpu\",\n",
    "                        #strategy=\"ddp_notebook\",\n",
    "                        precision=\"16-mixed\",\n",
    "                        gradient_clip_val=1.0,\n",
    "                        max_epochs=epochs,\n",
    "                        logger=logger,\n",
    "                        profiler=None,\n",
    "                        \n",
    "                    )\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:56.521265Z",
     "iopub.status.busy": "2025-04-12T05:07:56.520504Z",
     "iopub.status.idle": "2025-04-12T05:07:56.536230Z",
     "shell.execute_reply": "2025-04-12T05:07:56.535521Z",
     "shell.execute_reply.started": "2025-04-12T05:07:56.521239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "filters_des = {'same_8': [8,8,8,8,8], 'same_16':[16,16,16,16,16], 'same_32': [32,32,32,32,32], 'same_64': [64, 64, 64, 64, 64], 'increase_16_128':[16, 32, 64, 128, 128], 'decrease_128_16': [128, 128, 64, 32, 16], 'mixed': [16, 32, 64, 32, 16]}\n",
    "kernels_des = {'same_3': [3,3,3,3,3], 'same_5':[5,5,5,5,5], 'mix_3_5':[3,3,5,5,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:07:56.537641Z",
     "iopub.status.busy": "2025-04-12T05:07:56.536989Z",
     "iopub.status.idle": "2025-04-12T05:07:56.555328Z",
     "shell.execute_reply": "2025-04-12T05:07:56.554783Z",
     "shell.execute_reply.started": "2025-04-12T05:07:56.537619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    #'name': 'bayes_sweep_init',\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 3},\n",
    "    'parameters': {\n",
    "        'lr': {\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-4\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [16,32]\n",
    "        },\n",
    "        'filters': {\n",
    "            'values': [\n",
    "                #filters_des['same_8'],\n",
    "                #filters_des['same_16'],\n",
    "                filters_des['same_32'],\n",
    "                filters_des['same_64'],\n",
    "                filters_des['increase_16_128'],\n",
    "                #filters_des['decrease_128_16'],\n",
    "                filters_des['mixed']\n",
    "            ]\n",
    "        },\n",
    "        'kernel': {\n",
    "            'values': [\n",
    "                kernels_des['same_3'],\n",
    "                kernels_des['same_5'],\n",
    "                #kernels_des['same_7'],\n",
    "                kernels_des['mix_3_5']\n",
    "            ]\n",
    "        },\n",
    "        'pool_kernel': {\n",
    "            'values': [[2,2,2,2,2], [3,3,3,3,3], [2,2,2,3,3]]\n",
    "        },\n",
    "        'pool_stride': {\n",
    "            'values': [[1,1,1,1,1], [1,1,1,2,2],[1,1,1,1,2]]\n",
    "        },\n",
    "        'batchnorm': {\n",
    "            'values': [True,]   # False\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu', 'gelu', 'mish', ]   #'swish''selu'\n",
    "        },\n",
    "\n",
    "        'augmentation': {\n",
    "            'values': [True]   #, False\n",
    "        },\n",
    "        'dropout': {\n",
    "            'min': 0.3,\n",
    "            'max': 0.4\n",
    "        },\n",
    "        'ffn_size': {\n",
    "            'values': [128, 256]  #64\n",
    "        },\n",
    "        'epochs': {'values': [5]}, #10\n",
    "        'optim': {'values': ['adam']}      #'sgd', \n",
    "    }\n",
    "}\n",
    "\n",
    "#'augmentation': {\n",
    "#    'values': ['hflip', 'vflip', 'rotate', None]\n",
    "#},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:09:51.219123Z",
     "iopub.status.busy": "2025-04-12T05:09:51.218849Z",
     "iopub.status.idle": "2025-04-12T05:09:51.228244Z",
     "shell.execute_reply": "2025-04-12T05:09:51.227501Z",
     "shell.execute_reply.started": "2025-04-12T05:09:51.219103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def trainCNN(config=None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        config = wandb.config\n",
    "        \n",
    "        run.name = f\"A_{config.augmentation}_D_{config.dropout:.2f}_bn_{config.batchnorm}_ffn_{config.ffn_size}\"\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        try:\n",
    "            # Dataloading\n",
    "            train_transform = transforms(augmentation=config.augmentation)\n",
    "            val_transform = transforms(augmentation=False)\n",
    "            DATA_DIR = \"/kaggle/temp/inaturalist12k/inaturalist_12K\"\n",
    "            train_dataset_complete = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"train\"))\n",
    "            test_dataset = torchvision.datasets.ImageFolder(root=os.path.join(DATA_DIR, \"val\"))\n",
    "        \n",
    "            # Getting labels and random splitting/shuffling of each class examples\n",
    "            labels = np.array([entry[1] for entry in train_dataset_complete.samples])\n",
    "            split_fn = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 219)\n",
    "            train_ids, valid_ids = next(split_fn.split(np.zeros(len(labels)), labels))\n",
    "        \n",
    "            #train_dataset = Subset(train_dataset_complete, train_ids)\n",
    "            #alid_dataset = Subset(train_dataset_complete, valid_ids)\n",
    "\n",
    "            # Transforms\n",
    "            train_dataset = Augmentation(train_dataset_complete, train_ids, train_transform)\n",
    "            valid_dataset = Augmentation(train_dataset_complete, valid_ids, val_transform)\n",
    "\n",
    "        \n",
    "            # Dataloader\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size,\n",
    "                                                      shuffle=True, num_workers=NUM_WORKERS, pin_memory = False, worker_init_fn=seed_worker,\n",
    "                generator=g)\n",
    "        \n",
    "            val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.batch_size,\n",
    "                                                    shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n",
    "                generator=g)\n",
    "        \n",
    "            test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "                                                    shuffle=False, num_workers=NUM_WORKERS, pin_memory= False, worker_init_fn=seed_worker,\n",
    "                generator=g)\n",
    "        \n",
    "            classes = train_dataset_complete.classes\n",
    "            n_classes = len(classes)\n",
    "        \n",
    "        \n",
    "            # Model\n",
    "            model = CNN_light(optim= config.optim, filters= config.filters, kernel = config.kernel, pool_kernel=config.pool_kernel, pool_stride=config.pool_stride, batchnorm=config.batchnorm, activation=config.activation, dropout=config.dropout, ffn_size=config.ffn_size, lr=config.lr)\n",
    "            logger= WandbLogger(project= 'dlas2_sweeps', name = run.name, experiment=run, log_model = False)\n",
    "            trainer = pl.Trainer(\n",
    "                                    devices=1,\n",
    "                                    accelerator=\"gpu\",\n",
    "                                    #strategy=\"ddp_notebook\",\n",
    "                                    precision=\"16-mixed\",\n",
    "                                    gradient_clip_val=1.0,\n",
    "                                    max_epochs=config.epochs,\n",
    "                                    logger=logger,\n",
    "                                    profiler=None,\n",
    "                                    \n",
    "                                )\n",
    "\n",
    "            trainer.fit(model, train_dataloader, val_dataloader)\n",
    "        finally:\n",
    "            del trainer\n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T05:09:56.000114Z",
     "iopub.status.busy": "2025-04-12T05:09:55.999854Z",
     "iopub.status.idle": "2025-04-12T05:13:14.540928Z",
     "shell.execute_reply": "2025-04-12T05:13:14.539864Z",
     "shell.execute_reply.started": "2025-04-12T05:09:56.000098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"dla2-sweeps\")\n",
    "#sweep_id = \"deeplearn24/dla2-sweeps/9pjx0avr\"\n",
    "wandb.agent(sweep_id, function=trainCNN, count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "- ResNET\n",
    "- vis filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_light_finetune(pl.LightningModule):\n",
    "    def __init__(self, optim, lr):\n",
    "        super().__init__()\n",
    "        self.optim = optim\n",
    "        self.save_hyperparameters()\n",
    "        self.model = models.googlenet(pretrained=True)\n",
    "        self.model.fc = nn.Linear(in_features = 1024, out_features = 10, bias = True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = self.train_accuracy(logits, y)\n",
    "        self.log(\"train loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"train accuracy\", acc, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        acc = self.val_accuracy(logits, y)\n",
    "        self.log(\"val loss\", loss, on_step = False, on_epoch = True)\n",
    "        self.log(\"val accuracy\", acc, on_step = False, on_epoch = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9)\n",
    "        elif self.optim == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model = CNN_light_finetune(optim = 'adam', lr = 0.00005)\n",
    "logger= WandbLogger(project= 'finetune', name = 'test', log_model = False)\n",
    "trainer = pl.Trainer(\n",
    "                        devices=1,\n",
    "                        accelerator=\"gpu\",\n",
    "                        #strategy=\"ddp_notebook\",\n",
    "                        precision=\"16-mixed\",\n",
    "                        gradient_clip_val=1.0,\n",
    "                        max_epochs=epochs,\n",
    "                        logger=logger,\n",
    "                        profiler=None,\n",
    "                        \n",
    "                    )\n",
    "\n",
    "trainer.fit(finetune_model, train_dataloader, val_dataloader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7079686,
     "sourceId": 11318637,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
