{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning ResNet50 model on inaturalist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to demonstrate how finetuning of resnet50 model is finetuned on inaturalist dataset. Set configuration in `src/config.py`. Finetuning model using lightning is defined in `models.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import lightning as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import wandb\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "from src.dataloader import iNat_dataset\n",
    "from src.config import *\n",
    "from src.models import pretrained_light, Unfreeze_after_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging in to wandb\n",
    "os.environ['WANDB_API_KEY'] = \"API-KEY\"    # your API-KEY to be entered here\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting train, validation, and test dataloaders\n",
    "dataset = iNat_dataset(data_dir=data_dir, augmentation = aug, batch_size=batch_size, NUM_WORKERS=NUM_WORKERS)\n",
    "train_dataloader, val_dataloader, test_dataloader, classes, n_classes = dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning the model\n",
    "finetune_model = pretrained_light(optim = optim, n_classes = n_classes, lr = lr)\n",
    "callback = Unfreeze_after_epochs(unfreeze_at_epoch = unfreeze_at_epoch)                   # Freeze initial layers and unfreeze after given epochs\n",
    "logger= WandbLogger(project= project_name, name = run_name, log_model = False)\n",
    "trainer = pl.Trainer(\n",
    "                        devices=1,\n",
    "                        accelerator=\"auto\",\n",
    "                        precision=\"16-mixed\",\n",
    "                        gradient_clip_val=1.0,\n",
    "                        max_epochs=epochs,\n",
    "                        logger=logger,\n",
    "                        profiler=None,\n",
    "                        callbacks = [callback]\n",
    "                    )\n",
    "\n",
    "trainer.fit(finetune_model, train_dataloader, val_dataloader)\n",
    "trainer.test(finetune_model, dataloaders=test_dataloader)\n",
    "trainer.save_checkpoint(\"finetuned_model.ckpt\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
